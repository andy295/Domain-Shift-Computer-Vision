{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import numpy as np\n",
    "\n",
    "class Tester:\n",
    "    def __init__(self, model, dataloaders, device, loss_fn, num_classes):\n",
    "        self.__model = model\n",
    "        self.__data_loaders = dataloaders\n",
    "        self.__device = device\n",
    "        self.__loss_fn = loss_fn\n",
    "        self.__num_classes = num_classes\n",
    "\n",
    "    def test_step(self, test=False, eval=False, train=False):\n",
    "        \n",
    "        assert test + eval + train == 1, \"Exactly one of test, eval, or train must be True\"\n",
    "\n",
    "        if test:\n",
    "            assert isinstance(test, bool), \"test must be a boolean\"\n",
    "            data_loader = self.__data_loaders[\"test_loader\"]\n",
    "        elif eval:                    \n",
    "            assert isinstance(eval, bool), \"test must be a boolean\"\n",
    "            data_loader = self.__data_loaders[\"val_loader\"]\n",
    "        elif train:\n",
    "            assert isinstance(train, bool), \"test must be a boolean\"\n",
    "            data_loader = self.__data_loaders[\"train_loader\"]            \n",
    "        else:\n",
    "            raise ValueError(\"One of test, eval or train must be True\")\n",
    "\n",
    "        samples = 0.\n",
    "        cumulative_loss = 0.\n",
    "        correct_predictions = 0\n",
    "\n",
    "        num_samples = len(data_loader.dataset)\n",
    "        y_true = np.zeros(num_samples, dtype=int)\n",
    "        y_pred = np.zeros(num_samples, dtype=int)\n",
    "\n",
    "        self.__model.eval()\n",
    "\n",
    "        with torch.no_grad():\n",
    "            index = 0\n",
    "            for inputs, targets in data_loader:\n",
    "                inputs = inputs.to(self.__device)\n",
    "                targets = targets.to(self.__device)\n",
    "\n",
    "                outputs = self.__model(inputs)\n",
    "                \n",
    "                loss = self.__loss_fn(outputs, targets)\n",
    "\n",
    "                batch_size = inputs.shape[0]\n",
    "                samples += inputs.shape[0]\n",
    "                cumulative_loss += loss.item() \n",
    "                _, predicted = outputs.max(dim=1)\n",
    "                \n",
    "                correct_predictions += predicted.eq(targets).sum().item()\n",
    "                \n",
    "                y_true[index:index + batch_size] = targets.cpu().numpy()\n",
    "                y_pred[index:index + batch_size] = predicted.cpu().numpy()\n",
    "                index += batch_size\n",
    "\n",
    "        average_loss = cumulative_loss / samples\n",
    "        accuracy = correct_predictions / samples * 100\n",
    "        \n",
    "        return average_loss, accuracy\n",
    "    \n",
    "    def get_predictions(self, test=False, train=False, eval=False):\n",
    "\n",
    "        assert test + eval + train == 1, \"Exactly one of test, eval, or train must be True\"\n",
    "\n",
    "        if test:\n",
    "            assert isinstance(test, bool), \"test must be a boolean\"\n",
    "            data_loader = self.__data_loaders[\"test_loader\"]\n",
    "        elif eval:                    \n",
    "            assert isinstance(eval, bool), \"test must be a boolean\"\n",
    "            data_loader = self.__data_loaders[\"val_loader\"]\n",
    "        elif train:\n",
    "            assert isinstance(train, bool), \"test must be a boolean\"\n",
    "            data_loader = self.__data_loaders[\"train_loader\"]            \n",
    "        else:\n",
    "            raise ValueError(\"One of test, eval or train must be True\")\n",
    "        \n",
    "        num_samples = len(data_loader.dataset)\n",
    "\n",
    "        # Preallocate numpy arrays\n",
    "        y_true = np.zeros(num_samples, dtype=int)\n",
    "        y_pred = np.zeros(num_samples, dtype=int)\n",
    "        \n",
    "        self.__model.eval()\n",
    "\n",
    "        with torch.no_grad():\n",
    "            index = 0\n",
    "            for inputs, targets in data_loader:\n",
    "                inputs = inputs.to(self.__device)\n",
    "                targets = targets.to(self.__device)\n",
    "\n",
    "                batch_size = inputs.shape[0]\n",
    "                if not self.__model.__class__.__name__ == \"Network_Wrapper\":                \n",
    "                    outputs = self.__model(inputs)\n",
    "\n",
    "                    if isinstance(outputs, dict):\n",
    "                        predicted = torch.argmax(outputs['comb_outs'][0])               \n",
    "                    else:    \n",
    "                        _, predicted = outputs.max(dim=1)\n",
    "\n",
    "                else:\n",
    "                    netp = torch.nn.DataParallel(self.__model, device_ids=[0])\n",
    "                    _, _, _, outputs, _, _, _ = netp(inputs)\n",
    "                    _, predicted = torch.max(outputs.data, 1)\n",
    "                \n",
    "\n",
    "                y_true[index:index + batch_size] = targets.cpu().numpy()\n",
    "                y_pred[index:index + batch_size] = predicted.cpu().numpy()\n",
    "                index += batch_size\n",
    "        \n",
    "        return {\"y_true\": y_true, \"y_pred\" : y_pred}\n",
    "    \n",
    "    def top_k_accuracy(self, train=False, eval=False, test=False, k=5):\n",
    "        \n",
    "        assert test + eval + train == 1, \"Exactly one of test, eval, or train must be True\"\n",
    "\n",
    "        if test:\n",
    "            assert isinstance(test, bool), \"test must be a boolean\"\n",
    "            data_loader = self.__data_loaders[\"test_loader\"]\n",
    "        elif eval:                    \n",
    "            assert isinstance(eval, bool), \"test must be a boolean\"\n",
    "            data_loader = self.__data_loaders[\"val_loader\"]\n",
    "        elif train:\n",
    "            assert isinstance(train, bool), \"test must be a boolean\"\n",
    "            data_loader = self.__data_loaders[\"train_loader\"]            \n",
    "        else:\n",
    "            raise ValueError(\"One of test, eval or train must be True\")\n",
    "        \n",
    "        self.__model.eval()\n",
    "        top_k_correct = 0\n",
    "        total = 0\n",
    "\n",
    "        with torch.no_grad():\n",
    "            for inputs, targets in data_loader:\n",
    "                inputs = inputs.to(self.__device)\n",
    "                targets = targets.to(self.__device)\n",
    "\n",
    "                if not self.__model.__class__.__name__ == \"Network_Wrapper\":                \n",
    "                    outputs = self.__model(inputs)\n",
    "                else:\n",
    "                    netp = torch.nn.DataParallel(self.__model, device_ids=[0])\n",
    "                    _, _, _, outputs, _, _, _ = netp(inputs)\n",
    "                \n",
    "                _, top_k_preds = outputs.topk(k, dim=1, largest=True, sorted=True)\n",
    "                \n",
    "                # Check if the true labels are in the top k predictions\n",
    "                correct = top_k_preds.eq(targets.view(-1, 1).expand_as(top_k_preds))\n",
    "                \n",
    "                # Sum the number of correct predictions\n",
    "                top_k_correct += correct.sum().item()\n",
    "                total += targets.size(0)\n",
    "        \n",
    "        top_k_accuracy = top_k_correct / total\n",
    "        return top_k_accuracy\n",
    "    \n",
    "    def class_wise_accuracy(self):\n",
    "\n",
    "        preds_truth = self.get_predictions(test=True)\n",
    "        true_labels = preds_truth[\"y_true\"]\n",
    "        predictions = preds_truth[\"y_pred\"]\n",
    "\n",
    "        classes = np.unique(true_labels)\n",
    "        class_wise_accuracy = {}\n",
    "        for cls in classes:\n",
    "            correct = np.sum(predictions[true_labels == cls] == cls)\n",
    "            total = np.sum(true_labels == cls)\n",
    "            class_wise_accuracy[cls] = correct / total\n",
    "        return class_wise_accuracy\n",
    "    \n",
    "    def identify_top_misclassified_classes(self, k):\n",
    "\n",
    "        preds_truth = self.get_predictions(test=True)\n",
    "        true_labels = preds_truth[\"y_true\"]\n",
    "        predictions = preds_truth[\"y_pred\"]\n",
    "\n",
    "        misclassified = predictions != true_labels\n",
    "        misclassified_classes, counts = np.unique(true_labels[misclassified], return_counts=True)\n",
    "        sorted_indices = np.argsort(-counts)  \n",
    "\n",
    "        return misclassified_classes[sorted_indices[:k]], counts[sorted_indices[:k]]\n",
    "    \n",
    "    def get_top_misclassified_samples(self, k):\n",
    "        \n",
    "        num_samples = len(self.__data_loaders[\"test_loader\"].dataset)\n",
    "        y_true = np.zeros(num_samples, dtype=int)\n",
    "        y_pred = np.zeros(num_samples, dtype=int)\n",
    "        logits = np.zeros(num_samples, dtype=int)\n",
    "        index = 0\n",
    "\n",
    "        self.__model.eval()\n",
    "        with torch.no_grad():\n",
    "            for inputs, targets in self.__data_loaders[\"test_loader\"]:\n",
    "                inputs = inputs.to(self.__device)\n",
    "                targets = targets.to(self.__device)\n",
    "\n",
    "                batch_size = inputs.shape[0]\n",
    "                if not self.__model.__class__.__name__ == \"Network_Wrapper\":                \n",
    "                    outputs = self.__model(inputs)\n",
    "\n",
    "                    if isinstance(outputs, dict):\n",
    "                        predicted = torch.argmax(outputs['comb_outs'][0], dim=1)               \n",
    "                    else:    \n",
    "                        predicted = torch.argmax(outputs, dim=1) \n",
    "\n",
    "                else:\n",
    "                    netp = torch.nn.DataParallel(self.__model, device_ids=[0])\n",
    "                    _, _, _, outputs, _, _, _ = netp(inputs)\n",
    "                    _, predicted = torch.max(outputs.data, 1)\n",
    "\n",
    "                logits_batch = torch.nn.functional.softmax(outputs, dim=1)\n",
    "                logits_batch = torch.max(logits_batch, dim=1)[0]\n",
    "\n",
    "                y_true[index:index + batch_size] = targets.cpu().numpy()\n",
    "                y_pred[index:index + batch_size] = predicted.cpu().numpy()\n",
    "                logits[index:index + batch_size] = logits_batch.cpu().numpy()\n",
    "                index += batch_size\n",
    "\n",
    "        misclassified_indices = np.where(y_pred != y_true)[0]\n",
    "        sorted_indices = np.argsort(-logits[misclassified_indices], axis=0)[:k]\n",
    "\n",
    "        return misclassified_indices[sorted_indices]"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
