{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "3edfef31-8632-4479-aa56-c2378b4b1955",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Warning: the working directory was changed to /home/sagemaker-user/Domain-Shift-Computer-Vision\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-08-01 14:35:28.775539: I tensorflow/core/util/port.cc:111] oneDNN custom operations are on. You may see slightly different numerical results due to floating-point round-off errors from different computation orders. To turn them off, set the environment variable `TF_ENABLE_ONEDNN_OPTS=0`.\n",
      "2024-08-01 14:35:28.821608: E tensorflow/compiler/xla/stream_executor/cuda/cuda_dnn.cc:9342] Unable to register cuDNN factory: Attempting to register factory for plugin cuDNN when one has already been registered\n",
      "2024-08-01 14:35:28.821636: E tensorflow/compiler/xla/stream_executor/cuda/cuda_fft.cc:609] Unable to register cuFFT factory: Attempting to register factory for plugin cuFFT when one has already been registered\n",
      "2024-08-01 14:35:28.821645: E tensorflow/compiler/xla/stream_executor/cuda/cuda_blas.cc:1518] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\n",
      "2024-08-01 14:35:28.829138: I tensorflow/core/platform/cpu_feature_guard.cc:182] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.\n",
      "To enable the following instructions: SSE4.1 SSE4.2 AVX AVX2 AVX512F AVX512_VNNI FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import torchvision.transforms as T\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "from train_test.train import Trainer\n",
    "import torchvision.models as models\n",
    "\n",
    "from utility.get_data import S3ImageFolder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "f195d3ac-4dc4-4855-a344-38d9f2d02d42",
   "metadata": {},
   "outputs": [],
   "source": [
    "imagenet_a_path = \"imagenet-a\"\n",
    "imagenet_b_path = \"imagenetv2-matched-frequency-format-val/\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "4f9966e7-0d0a-4c1f-879d-a9d1782151ed",
   "metadata": {
    "editable": true,
    "slideshow": {
     "slide_type": ""
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "def get_data(batch_size, img_root, seed, transform = None):\n",
    "\n",
    "    # Load data\n",
    "    data = S3ImageFolder(root=img_root, transform=transform)\n",
    "    \n",
    "    # Create train and test splits (80/20)\n",
    "    num_samples = len(data)\n",
    "    training_samples = int(num_samples * 0.8 + 1)\n",
    "    val_samples = int(num_samples * 0.1)\n",
    "    test_samples = num_samples - training_samples - val_samples\n",
    "\n",
    "    torch.manual_seed(seed)\n",
    "    training_data, val_data, test_data = torch.utils.data.random_split(data, [training_samples, val_samples, test_samples])\n",
    "    \n",
    "    # Initialize dataloaders\n",
    "    train_loader = torch.utils.data.DataLoader(training_data, batch_size, shuffle=True, num_workers=4)\n",
    "    val_loader = torch.utils.data.DataLoader(val_data, batch_size, shuffle=False, num_workers=4)\n",
    "    test_loader = torch.utils.data.DataLoader(test_data, batch_size, shuffle=False, num_workers=4)\n",
    "\n",
    "    return train_loader, val_loader, test_loader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "24775509-0a31-4141-89e9-09cceada7052",
   "metadata": {},
   "outputs": [],
   "source": [
    "transform = T.Compose([\n",
    "        T.Resize((256, 256)),\n",
    "        T.RandomCrop((224, 224)),\n",
    "        T.ToTensor(),\n",
    "        #T.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225])\n",
    "    ])\n",
    "\n",
    "train_loader, val_loader, test_loader = get_data(batch_size=32, \n",
    "                                                 img_root=imagenet_a_path, \n",
    "                                                 transform = transform, \n",
    "                                                 seed=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "9e5158cd-8d3f-4f7c-83ee-cade11170257",
   "metadata": {},
   "outputs": [],
   "source": [
    "data_loaders = {\n",
    "    \"train_loader\": train_loader,\n",
    "    \"val_loader\": val_loader,\n",
    "    \"test_loader\": test_loader,\n",
    "}     "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "3640406d-cddc-472e-abe5-748286517eb2",
   "metadata": {
    "editable": true,
    "slideshow": {
     "slide_type": ""
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/lib/python3.10/site-packages/torchvision/models/_utils.py:208: UserWarning: The parameter 'pretrained' is deprecated since 0.13 and may be removed in the future, please use 'weights' instead.\n",
      "  warnings.warn(\n",
      "/opt/conda/lib/python3.10/site-packages/torchvision/models/_utils.py:223: UserWarning: Arguments other than a weight enum or `None` for 'weights' are deprecated since 0.13 and may be removed in the future. The current behavior is equivalent to passing `weights=ResNet50_Weights.IMAGENET1K_V1`. You can also use `weights=ResNet50_Weights.DEFAULT` to get the most up-to-date weights.\n",
      "  warnings.warn(msg)\n"
     ]
    }
   ],
   "source": [
    "model = models.resnet50(pretrained=True)\n",
    "num_features = model.fc.in_features\n",
    "model.fc = nn.Linear(num_features, 1000)\n",
    "\n",
    "for param in model.parameters():\n",
    "    param.requires_grad = False\n",
    "\n",
    "for param in model.fc.parameters():\n",
    "    param.requires_grad = True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "85d9c7f3-022c-4b0c-ac23-7d911c13430e",
   "metadata": {},
   "outputs": [],
   "source": [
    "optimizer = torch.optim.SGD(model.parameters(), lr=0.1, momentum=0.9, weight_decay=0.005)\n",
    "device = torch.device(\"cuda\") if torch.cuda.is_available() else torch.device(\"cpu\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "66d943ff-0ff5-4927-93d6-20d873b6b968",
   "metadata": {},
   "outputs": [],
   "source": [
    "# checkpoint = torch.load(\"/home/sagemaker-user/Domain-Shift-Computer-Vision/experiments/Resnet50_ImagenetA_SGD/checkpoint.pth\")\n",
    "# model.load_state_dict(checkpoint[\"model\"])\n",
    "# optimizer.load_state_dict(checkpoint[\"optimizer\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "be74f3c1-1926-4676-8e4e-edfcbd2b8ecc",
   "metadata": {},
   "outputs": [],
   "source": [
    "model_trainer = Trainer(data_loaders=data_loaders,\n",
    "                         dataset_name=\"Imagenet-A\",\n",
    "                         model=model,\n",
    "                         optimizer=optimizer,\n",
    "                         loss_fn=nn.CrossEntropyLoss(),\n",
    "                         device=device,\n",
    "                         seed=42,\n",
    "                         exp_path=\"/home/sagemaker-user/Domain-Shift-Computer-Vision/experiments\",\n",
    "                         exp_name=\"Resnet50_ImagenetA_SGD_1\",\n",
    "                         use_early_stopping=True,\n",
    "                         trained = False\n",
    "                       )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5c972a59-afaf-49db-a884-2d7e5dc0de18",
   "metadata": {
    "editable": true,
    "slideshow": {
     "slide_type": ""
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Resnet50: 6 epochs, early stopping\n",
    "for i in range(2):\n",
    "    model_trainer.main(epochs=3,\n",
    "                       log_interval=0.01)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4ccf5c0e-4890-42f1-af9c-c8009b5d4a71",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# visualize with tensorboard\n",
    "%reload_ext tensorboard\n",
    "%tensorboard --logdir=/home/sagemaker-user/Domain-Shift-Computer-Vision/experiments # experiment path"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fc3ba877-1c7e-41ff-a1cf-b16f73f9892e",
   "metadata": {},
   "source": [
    "-----"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b1ddb39b-484b-40a8-a6e1-763d3071ddb9",
   "metadata": {},
   "source": [
    "# MEMO"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "e146ddd9-1245-4760-9342-6b73d90fd9b9",
   "metadata": {},
   "outputs": [],
   "source": [
    "from MEMO.MEMO import MEMO"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "360b95ba-5779-4f68-8a22-e51a734e2f9d",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "checkpoint_path = \"/home/sagemaker-user/Domain-Shift-Computer-Vision/experiments/Resnet50_ImagenetA_SGD/checkpoint.pth\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "5ace4045-d733-4897-95fd-f667a42acc60",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/lib/python3.10/site-packages/torchvision/models/_utils.py:208: UserWarning: The parameter 'pretrained' is deprecated since 0.13 and may be removed in the future, please use 'weights' instead.\n",
      "  warnings.warn(\n",
      "/opt/conda/lib/python3.10/site-packages/torchvision/models/_utils.py:223: UserWarning: Arguments other than a weight enum or `None` for 'weights' are deprecated since 0.13 and may be removed in the future. The current behavior is equivalent to passing `weights=ResNet50_Weights.IMAGENET1K_V1`. You can also use `weights=ResNet50_Weights.DEFAULT` to get the most up-to-date weights.\n",
      "  warnings.warn(msg)\n"
     ]
    }
   ],
   "source": [
    "model = models.resnet50(pretrained=True)\n",
    "num_features = model.fc.in_features\n",
    "model.fc = nn.Linear(num_features, 1000)\n",
    "\n",
    "for param in model.parameters():\n",
    "    param.requires_grad = False\n",
    "\n",
    "for param in model.fc.parameters():\n",
    "    param.requires_grad = True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "074ae947-275e-4738-a930-14c071db2c63",
   "metadata": {},
   "outputs": [],
   "source": [
    "optimizer = torch.optim.SGD(model.parameters(), lr=0.1, momentum=0.9, weight_decay=0.005)\n",
    "device = torch.device(\"cuda\") if torch.cuda.is_available() else torch.device(\"cpu\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "31a14b6b-c730-4fd5-a9a9-6607e098ddb3",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torchvision.transforms as T\n",
    "\n",
    "# List of augmentations\n",
    "augmentations = [\n",
    "    T.RandomHorizontalFlip(p=0.5),\n",
    "    T.RandomVerticalFlip(p=0.5),\n",
    "    T.RandomRotation(degrees=45),\n",
    "    T.ColorJitter(brightness=0.5, contrast=0.5, saturation=0.5, hue=0.5),\n",
    "    T.RandomGrayscale(p=0.2),\n",
    "    T.RandomAffine(degrees=0, translate=(0.1, 0.1)),\n",
    "    T.RandomPerspective(distortion_scale=0.5, p=0.5),\n",
    "    T.RandomErasing(p=0.5),\n",
    "    T.GaussianBlur(kernel_size=(5, 9), sigma=(0.1, 5)),\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "56d52a8d-d16a-4f90-a4e0-a2660a711bd1",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(12.661219298123358, 97.46328437917224)"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "MEMO(model = model,\n",
    "     optimizer = optimizer,\n",
    "     device = device,\n",
    "     augmentations = augmentations, \n",
    "     num_augmentations = 5, \n",
    "     seed = 42, \n",
    "     batch_size = 32, \n",
    "     img_root = imagenet_a_path, \n",
    "     checkpoint_path = checkpoint_path, \n",
    "     loss = F.cross_entropy\n",
    "    )"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.14"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
