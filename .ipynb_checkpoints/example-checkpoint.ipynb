{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "3edfef31-8632-4479-aa56-c2378b4b1955",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Warning: the working directory was changed to /home/sagemaker-user/Domain-Shift-Computer-Vision\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-08-02 10:32:42.981423: I tensorflow/core/util/port.cc:111] oneDNN custom operations are on. You may see slightly different numerical results due to floating-point round-off errors from different computation orders. To turn them off, set the environment variable `TF_ENABLE_ONEDNN_OPTS=0`.\n",
      "2024-08-02 10:32:43.548975: E tensorflow/compiler/xla/stream_executor/cuda/cuda_dnn.cc:9342] Unable to register cuDNN factory: Attempting to register factory for plugin cuDNN when one has already been registered\n",
      "2024-08-02 10:32:43.549011: E tensorflow/compiler/xla/stream_executor/cuda/cuda_fft.cc:609] Unable to register cuFFT factory: Attempting to register factory for plugin cuFFT when one has already been registered\n",
      "2024-08-02 10:32:43.549033: E tensorflow/compiler/xla/stream_executor/cuda/cuda_blas.cc:1518] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\n",
      "2024-08-02 10:32:43.818479: I tensorflow/core/platform/cpu_feature_guard.cc:182] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.\n",
      "To enable the following instructions: SSE4.1 SSE4.2 AVX AVX2 AVX512F AVX512_VNNI FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import torchvision.transforms as T\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "from train_test.train import Trainer\n",
    "import torchvision.models as models\n",
    "\n",
    "from utility.get_data import S3ImageFolder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "f195d3ac-4dc4-4855-a344-38d9f2d02d42",
   "metadata": {},
   "outputs": [],
   "source": [
    "imagenet_a_path = \"imagenet-a\"\n",
    "imagenet_b_path = \"imagenetv2-matched-frequency-format-val/\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "4f9966e7-0d0a-4c1f-879d-a9d1782151ed",
   "metadata": {
    "editable": true,
    "slideshow": {
     "slide_type": ""
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "def get_data(batch_size, img_root, seed, transform = None):\n",
    "\n",
    "    # Load data\n",
    "    data = S3ImageFolder(root=img_root, transform=transform)\n",
    "    \n",
    "    # Create train and test splits (80/20)\n",
    "    num_samples = len(data)\n",
    "    training_samples = int(num_samples * 0.8 + 1)\n",
    "    val_samples = int(num_samples * 0.1)\n",
    "    test_samples = num_samples - training_samples - val_samples\n",
    "\n",
    "    torch.manual_seed(seed)\n",
    "    training_data, val_data, test_data = torch.utils.data.random_split(data, [training_samples, val_samples, test_samples])\n",
    "    \n",
    "    # Initialize dataloaders\n",
    "    train_loader = torch.utils.data.DataLoader(training_data, batch_size, shuffle=True, num_workers=4)\n",
    "    val_loader = torch.utils.data.DataLoader(val_data, batch_size, shuffle=False, num_workers=4)\n",
    "    test_loader = torch.utils.data.DataLoader(test_data, batch_size, shuffle=False, num_workers=4)\n",
    "\n",
    "    return train_loader, val_loader, test_loader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "24775509-0a31-4141-89e9-09cceada7052",
   "metadata": {},
   "outputs": [],
   "source": [
    "transform = T.Compose([\n",
    "        T.Resize((256, 256)),\n",
    "        T.RandomCrop((224, 224)),\n",
    "        T.ToTensor(),\n",
    "        T.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225])\n",
    "    ])\n",
    "\n",
    "train_loader, val_loader, test_loader = get_data(batch_size=32, \n",
    "                                                 img_root=imagenet_a_path, \n",
    "                                                 transform = transform, \n",
    "                                                 seed=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "9e5158cd-8d3f-4f7c-83ee-cade11170257",
   "metadata": {},
   "outputs": [],
   "source": [
    "data_loaders = {\n",
    "    \"train_loader\": train_loader,\n",
    "    \"val_loader\": val_loader,\n",
    "    \"test_loader\": test_loader,\n",
    "}     "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "3640406d-cddc-472e-abe5-748286517eb2",
   "metadata": {
    "editable": true,
    "slideshow": {
     "slide_type": ""
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/lib/python3.10/site-packages/torchvision/models/_utils.py:208: UserWarning: The parameter 'pretrained' is deprecated since 0.13 and may be removed in the future, please use 'weights' instead.\n",
      "  warnings.warn(\n",
      "/opt/conda/lib/python3.10/site-packages/torchvision/models/_utils.py:223: UserWarning: Arguments other than a weight enum or `None` for 'weights' are deprecated since 0.13 and may be removed in the future. The current behavior is equivalent to passing `weights=ResNet50_Weights.IMAGENET1K_V1`. You can also use `weights=ResNet50_Weights.DEFAULT` to get the most up-to-date weights.\n",
      "  warnings.warn(msg)\n"
     ]
    }
   ],
   "source": [
    "model = models.resnet50(pretrained=True)\n",
    "num_features = model.fc.in_features\n",
    "model.fc = nn.Linear(num_features, 1000)\n",
    "\n",
    "for param in model.parameters():\n",
    "    param.requires_grad = False\n",
    "\n",
    "for param in model.fc.parameters():\n",
    "    param.requires_grad = True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "85d9c7f3-022c-4b0c-ac23-7d911c13430e",
   "metadata": {},
   "outputs": [],
   "source": [
    "optimizer = torch.optim.SGD(model.parameters(), lr=0.1, momentum=0.9, weight_decay=0.005)\n",
    "device = torch.device(\"cuda\") if torch.cuda.is_available() else torch.device(\"cpu\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "66d943ff-0ff5-4927-93d6-20d873b6b968",
   "metadata": {},
   "outputs": [],
   "source": [
    "# checkpoint = torch.load(\"/home/sagemaker-user/Domain-Shift-Computer-Vision/experiments/Resnet50_ImagenetA_SGD/checkpoint.pth\")\n",
    "# model.load_state_dict(checkpoint[\"model\"])\n",
    "# optimizer.load_state_dict(checkpoint[\"optimizer\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "be74f3c1-1926-4676-8e4e-edfcbd2b8ecc",
   "metadata": {},
   "outputs": [],
   "source": [
    "model_trainer = Trainer(data_loaders=data_loaders,\n",
    "                         dataset_name=\"Imagenet-A\",\n",
    "                         model=model,\n",
    "                         optimizer=optimizer,\n",
    "                         loss_fn=nn.CrossEntropyLoss(),\n",
    "                         device=device,\n",
    "                         seed=42,\n",
    "                         exp_path=\"/home/sagemaker-user/Domain-Shift-Computer-Vision/experiments\",\n",
    "                         exp_name=\"Resnet50_ImagenetA_SGD_1\",\n",
    "                         use_early_stopping=True,\n",
    "                         trained = False\n",
    "                       )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5c972a59-afaf-49db-a884-2d7e5dc0de18",
   "metadata": {
    "editable": true,
    "slideshow": {
     "slide_type": ""
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Resnet50: 6 epochs, early stopping\n",
    "for i in range(2):\n",
    "    model_trainer.main(epochs=3,\n",
    "                       log_interval=0.01)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4ccf5c0e-4890-42f1-af9c-c8009b5d4a71",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# visualize with tensorboard\n",
    "%reload_ext tensorboard\n",
    "%tensorboard --logdir=/home/sagemaker-user/Domain-Shift-Computer-Vision/experiments # experiment path"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fc3ba877-1c7e-41ff-a1cf-b16f73f9892e",
   "metadata": {},
   "source": [
    "-----"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b1ddb39b-484b-40a8-a6e1-763d3071ddb9",
   "metadata": {},
   "source": [
    "# MEMO"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "1851005d-1fc7-4abd-a04f-5550b7067939",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Warning: the working directory was changed to /home/sagemaker-user/Domain-Shift-Computer-Vision\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-08-02 11:07:27.838369: I tensorflow/core/util/port.cc:111] oneDNN custom operations are on. You may see slightly different numerical results due to floating-point round-off errors from different computation orders. To turn them off, set the environment variable `TF_ENABLE_ONEDNN_OPTS=0`.\n",
      "2024-08-02 11:07:27.884218: E tensorflow/compiler/xla/stream_executor/cuda/cuda_dnn.cc:9342] Unable to register cuDNN factory: Attempting to register factory for plugin cuDNN when one has already been registered\n",
      "2024-08-02 11:07:27.884249: E tensorflow/compiler/xla/stream_executor/cuda/cuda_fft.cc:609] Unable to register cuFFT factory: Attempting to register factory for plugin cuFFT when one has already been registered\n",
      "2024-08-02 11:07:27.884258: E tensorflow/compiler/xla/stream_executor/cuda/cuda_blas.cc:1518] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\n",
      "2024-08-02 11:07:27.891420: I tensorflow/core/platform/cpu_feature_guard.cc:182] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.\n",
      "To enable the following instructions: SSE4.1 SSE4.2 AVX AVX2 AVX512F AVX512_VNNI FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import torchvision.transforms as T\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "from train_test.train import Trainer\n",
    "import torchvision.models as models\n",
    "\n",
    "from utility.get_data import S3ImageFolder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "e146ddd9-1245-4760-9342-6b73d90fd9b9",
   "metadata": {},
   "outputs": [],
   "source": [
    "from MEMO.MEMO import MEMO"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "990934cc-7795-415b-adbd-17227bed3510",
   "metadata": {},
   "outputs": [],
   "source": [
    "imagenet_a_path = \"imagenet-a\"\n",
    "imagenet_b_path = \"imagenetv2-matched-frequency-format-val/\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "360b95ba-5779-4f68-8a22-e51a734e2f9d",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "checkpoint_path = \"/home/sagemaker-user/Domain-Shift-Computer-Vision/experiments/Resnet50_ImagenetA_SGD/checkpoint.pth\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "5ace4045-d733-4897-95fd-f667a42acc60",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = models.resnet50(weights=\"IMAGENET1K_V1\")\n",
    "num_features = model.fc.in_features\n",
    "model.fc = nn.Linear(num_features, 1000)\n",
    "\n",
    "for param in model.parameters():\n",
    "    param.requires_grad = False\n",
    "\n",
    "for param in model.fc.parameters():\n",
    "    param.requires_grad = True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "074ae947-275e-4738-a930-14c071db2c63",
   "metadata": {},
   "outputs": [],
   "source": [
    "optimizer = torch.optim.SGD(model.parameters(), lr=0.1, momentum=0.9, weight_decay=0.005)\n",
    "device = torch.device(\"cuda\") if torch.cuda.is_available() else torch.device(\"cpu\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a82f9c64-35ae-4813-b46b-012bba1d9cfa",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torchvision.transforms as T\n",
    "\n",
    "augmentations = [\n",
    "    T.RandomHorizontalFlip(p=1),\n",
    "    T.RandomVerticalFlip(p=1),\n",
    "    T.RandomRotation(degrees=30),\n",
    "    T.RandomRotation(degrees=60),\n",
    "    T.ColorJitter(brightness=0.2),\n",
    "    T.ColorJitter(contrast=0.2),\n",
    "    T.ColorJitter(saturation=0.2),\n",
    "    T.ColorJitter(hue=0.2),\n",
    "    #T.RandomAffine(degrees=0, translate=(0.1, 0.1)),\n",
    "    #T.RandomRotation(degrees=15),\n",
    "    #T.RandomAdjustSharpness(sharpness_factor=2, p=1),\n",
    "    #T.RandomGrayscale(p=1),\n",
    "    #T.RandomInvert(p=1),\n",
    "    #T.RandomAutocontrast(p=1),\n",
    "    #T.GaussianBlur(kernel_size=5),\n",
    "    #T.RandomPerspective(distortion_scale=0.5, p=1.0),\n",
    "    #T.RandomErasing(p=1),\n",
    "    #T.ElasticTransform(alpha=1.0)\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "31a14b6b-c730-4fd5-a9a9-6607e098ddb3",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torchvision.transforms as T\n",
    "\n",
    "# List of augmentations\n",
    "augmentations = [\n",
    "    T.RandomHorizontalFlip(p=1),\n",
    "    T.RandomVerticalFlip(p=1),\n",
    "    T.RandomRotation(degrees=30),\n",
    "    T.RandomRotation(degrees=60),\n",
    "    T.ColorJitter(brightness=0.2),\n",
    "    T.ColorJitter(contrast=0.2),\n",
    "    T.ColorJitter(saturation=0.2),\n",
    "    T.ColorJitter(hue=0.2),\n",
    "    T.RandomAffine(degrees=0, translate=(0.1, 0.1)),\n",
    "    T.RandomRotation(degrees=15),\n",
    "    T.RandomAdjustSharpness(sharpness_factor=2, p=1),\n",
    "    T.RandomGrayscale(p=1),\n",
    "    T.RandomInvert(p=1),\n",
    "    T.RandomAutocontrast(p=1),\n",
    "    T.GaussianBlur(kernel_size=5),\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "9c522c6a-84b6-453d-8921-5a9af1e9453e",
   "metadata": {},
   "outputs": [],
   "source": [
    "MEMO_resnet50 = MEMO(model, optimizer, checkpoint_path, device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "f1bb98e4-9b44-40b6-b343-3599f1eaff9f",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/lib/python3.10/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "accuracy: 8.01068090787717\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "8.01068090787717"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "MEMO_resnet50.test_MEMO(\n",
    "     augmentations = augmentations, \n",
    "     num_augmentations = 8, \n",
    "     seed = 42, \n",
    "     batch_size = 32, \n",
    "     img_root = imagenet_a_path,\n",
    "     top_k = \"diff_aug\",\n",
    "     MEMO = True\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c5967e04-3b52-49ad-ab85-4e90f04581a2",
   "metadata": {},
   "source": [
    "## TEST (MEMO TOO GOOD)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "56d52a8d-d16a-4f90-a4e0-a2660a711bd1",
   "metadata": {},
   "outputs": [],
   "source": [
    "input, image_augmented, target = MEMO_resnet50.test_MEMO(\n",
    "     augmentations = augmentations, \n",
    "     num_augmentations = 5, \n",
    "     seed = 42, \n",
    "     batch_size = 32, \n",
    "     img_root = imagenet_a_path, \n",
    "     loss = F.cross_entropy\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "17ca1dcf-f39e-46ff-bc76-3a0a70bab226",
   "metadata": {},
   "outputs": [],
   "source": [
    "checkpoint = torch.load(checkpoint_path)\n",
    "model.load_state_dict(checkpoint[\"model\"])\n",
    "model.train()\n",
    "model.to(device) \n",
    "optimizer.load_state_dict(checkpoint[\"optimizer\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "f7e8445f-70ce-4ef2-b77d-18699dde44a6",
   "metadata": {},
   "outputs": [],
   "source": [
    "outputs = model(image_augmented)\n",
    "marginal_output_distribution = torch.mean(outputs, dim=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "44edf3c2-9041-4343-b867-c083b4d8a3f5",
   "metadata": {},
   "outputs": [],
   "source": [
    "marginal_output_distribution_probab = torch.softmax(outputs, dim=1).mean(dim=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "03aad9d5-95b9-4e2d-9b7b-031847518ca1",
   "metadata": {},
   "outputs": [],
   "source": [
    "def compute_entropy(probabilities):\n",
    "    # Ensure probabilities are normalized (sum to 1)\n",
    "    if not torch.isclose(probabilities.sum(), torch.tensor(1.0)):\n",
    "        raise ValueError(\"The probabilities should sum to 1.\")\n",
    "    \n",
    "    # Compute entropy\n",
    "    # Adding a small value to avoid log(0) issues\n",
    "    epsilon = 1e-10\n",
    "    probabilities = torch.clamp(probabilities, min=epsilon)\n",
    "    entropy = -torch.sum(probabilities * torch.log(probabilities))\n",
    "    \n",
    "    return entropy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "2314d3c9-402f-4730-a04b-25d88a1c98c1",
   "metadata": {},
   "outputs": [],
   "source": [
    "marginal_loss = compute_entropy(marginal_output_distribution_probab)\n",
    "marginal_loss.backward()\n",
    "optimizer.step()\n",
    "optimizer.zero_grad()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "d344ea8a-3424-43de-a395-45f2c0b863b1",
   "metadata": {},
   "outputs": [],
   "source": [
    "marginal_loss = F.cross_entropy(marginal_output_distribution, target)\n",
    "marginal_loss.backward()\n",
    "optimizer.step()\n",
    "optimizer.zero_grad()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "6e1d60e1-0eab-48ed-9424-fcb4bea25e39",
   "metadata": {},
   "outputs": [],
   "source": [
    "input = T.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225])(input)\n",
    "probab_pred = torch.softmax(model(input.unsqueeze(0)), dim=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "id": "bd2d19c0-cdd5-44f1-80d7-ccf1f699953f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1"
      ]
     },
     "execution_count": 53,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "probab_pred.shape[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "d3fa0be0-a726-4331-aeee-490052e1533d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor(True, device='cuda:0')"
      ]
     },
     "execution_count": 50,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_pred = probab_pred.argmax()\n",
    "y_pred == target"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.14"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
