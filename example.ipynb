{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "b1ddb39b-484b-40a8-a6e1-763d3071ddb9",
   "metadata": {},
   "source": [
    "# Test-Time Adaptation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "1851005d-1fc7-4abd-a04f-5550b7067939",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torchvision.transforms as T\n",
    "import torchvision.models as models\n",
    "import torchvision\n",
    "from test_methods.test import Tester\n",
    "from test_time_adaptation.resnet50_dropout import ResNet50Dropout"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "990934cc-7795-415b-adbd-17227bed3510",
   "metadata": {},
   "outputs": [],
   "source": [
    "imagenet_a_path = \"imagenet-a\"\n",
    "imagenet_b_path = \"imagenetv2-matched-frequency-format-val/\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "5ace4045-d733-4897-95fd-f667a42acc60",
   "metadata": {},
   "outputs": [],
   "source": [
    "device = torch.device(\"cuda\") if torch.cuda.is_available() else torch.device(\"cpu\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "31a14b6b-c730-4fd5-a9a9-6607e098ddb3",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torchvision.transforms as T\n",
    "\n",
    "augmentations = [\n",
    "    T.RandomHorizontalFlip(p=1),\n",
    "    T.RandomVerticalFlip(p=1),\n",
    "    T.RandomRotation(degrees=30),\n",
    "    T.RandomRotation(degrees=60),\n",
    "    T.ColorJitter(brightness=0.2),\n",
    "    T.ColorJitter(contrast=0.2),\n",
    "    T.ColorJitter(saturation=0.2),\n",
    "    T.ColorJitter(hue=0.2),\n",
    "    T.RandomAffine(degrees=0, translate=(0.1, 0.1)),\n",
    "    T.RandomRotation(degrees=15),\n",
    "    T.RandomAdjustSharpness(sharpness_factor=2, p=1),\n",
    "    T.RandomGrayscale(p=1),\n",
    "    T.RandomInvert(p=1),\n",
    "    T.RandomAutocontrast(p=1),\n",
    "    T.GaussianBlur(kernel_size=5),\n",
    "]\n",
    "\n",
    "augmix_augmentations = [\n",
    "    T.AugMix(severity=3, mixture_width=3, chain_depth=3, alpha=1.0),\n",
    "    T.AugMix(severity=2, mixture_width=2, chain_depth=3, alpha=1.0),\n",
    "    T.AugMix(severity=4, mixture_width=4, chain_depth=3, alpha=1.0),\n",
    "    T.AugMix(severity=3, mixture_width=3, chain_depth=3, alpha=1.0),\n",
    "    T.AugMix(severity=2, mixture_width=2, chain_depth=3, alpha=1.0),\n",
    "    T.AugMix(severity=4, mixture_width=4, chain_depth=3, alpha=1.0),\n",
    "    T.AugMix(severity=3, mixture_width=3, chain_depth=3, alpha=1.0),\n",
    "    T.AugMix(severity=2, mixture_width=2, chain_depth=3, alpha=1.0),\n",
    "    T.AugMix(severity=4, mixture_width=4, chain_depth=3, alpha=1.0),\n",
    "    T.AugMix(severity=3, mixture_width=3, chain_depth=3, alpha=1.0),\n",
    "    T.AugMix(severity=2, mixture_width=2, chain_depth=3, alpha=1.0),\n",
    "    T.AugMix(severity=4, mixture_width=4, chain_depth=3, alpha=1.0),\n",
    "    T.AugMix(severity=3, mixture_width=3, chain_depth=3, alpha=1.0),\n",
    "    T.AugMix(severity=2, mixture_width=2, chain_depth=3, alpha=1.0),\n",
    "    T.AugMix(severity=4, mixture_width=4, chain_depth=3, alpha=1.0),\n",
    "    T.AugMix(severity=3, mixture_width=3, chain_depth=3, alpha=1.0),\n",
    "    T.AugMix(severity=2, mixture_width=2, chain_depth=3, alpha=1.0),\n",
    "    T.AugMix(severity=4, mixture_width=4, chain_depth=3, alpha=1.0)\n",
    "]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "08b444fa-d1e4-412d-814f-36ba12981ff0",
   "metadata": {},
   "source": [
    "## Resnet50"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "3e752756-e914-48e7-a203-21ae62dba5ac",
   "metadata": {},
   "outputs": [],
   "source": [
    "exp_path_a = \"/home/sagemaker-user/Domain-Shift-Computer-Vision/experiments/Resnet50_ImagenetA_SGD\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "5cf183bc",
   "metadata": {},
   "outputs": [],
   "source": [
    "MC = {\n",
    "\t\"dropout_rate\": 0.5,\n",
    "\t\"num_samples\": 10,\n",
    "\t\"use_dropout\": False\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "9c522c6a-84b6-453d-8921-5a9af1e9453e",
   "metadata": {},
   "outputs": [],
   "source": [
    "tester_resnet50 = Tester(\n",
    "    model = ResNet50Dropout() if MC['use_dropout'] else models.resnet50,\n",
    "    optimizer = torch.optim.SGD,\n",
    "    exp_path = exp_path_a,\n",
    "    device = device\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "7c6041ec-e1e3-4d1a-a419-f86a79c1ac79",
   "metadata": {},
   "outputs": [],
   "source": [
    "#lr_setting = [{\n",
    "#    \"classifier\" : [[\"fc.weight\", \"fc.bias\"], 0.00025]    \n",
    "#}, 0]\n",
    "lr_setting_sgd = [0.00025] # setting used in MEMO paper for SGD\n",
    "lr_setting_adam = [0.0001] # setting used in MEMO paper for ADAM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "200a4ed2-9d24-4de5-8da4-01c8ade487b1",
   "metadata": {},
   "outputs": [],
   "source": [
    "imagenetV1_weights = models.ResNet50_Weights.IMAGENET1K_V1 # MEMO paper used these weights\n",
    "imagenetV2_weights = models.ResNet50_Weights.IMAGENET1K_V2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "e847161c-c688-4ec6-aaa8-4fbbc67baff5",
   "metadata": {},
   "outputs": [],
   "source": [
    "gen_aug_settings = {\n",
    "    \"clip_img_encoder\" : \"ViT-L/14\",\n",
    "    \"num_img\" : 30,\n",
    "    \"gen_data_path\" : \"/home/sagemaker-user/Domain-Shift-Computer-Vision/imagenetA_generated\",\n",
    "    \"use_t2i_similarity\" : True,\n",
    "    \"t2i_img\" : True,\n",
    "    \"i2i_img\" : False,\n",
    "    \"threshold\" : 0.7\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f1bb98e4-9b44-40b6-b343-3599f1eaff9f",
   "metadata": {},
   "outputs": [],
   "source": [
    "tester_resnet50.test(\n",
    "     augmentations = augmix_augmentations, \n",
    "     num_augmentations = 16,\n",
    "     seed_augmentations = 42,\n",
    "     batch_size = 64, \n",
    "     img_root = imagenet_a_path,\n",
    "     num_adaptation_steps = 2,\n",
    "     MEMO = True,\n",
    "     lr_setting = lr_setting_sgd,\n",
    "     top_augmentations = 0, # if using gen_aug run with 0 bc otherwise might not be used at all\n",
    "     weights_imagenet = imagenetV1_weights,\n",
    "     prior_strength = 16,\n",
    "     TTA = True,\n",
    "     MC = None,\n",
    "     gen_aug_settings = gen_aug_settings\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8e5a3855-f888-4eea-af94-77a123dc58a2",
   "metadata": {},
   "source": [
    "## Image Generation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1f230e3f-5566-4d7c-863c-835a5ff5a6fc",
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip install ollama"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "20c37523-1bff-415c-b483-523e0b4a15ad",
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip install diffusers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c46a892a-b689-41cf-9a1a-c208df0f70d4",
   "metadata": {},
   "outputs": [],
   "source": [
    "! pip install git+https://github.com/openai/CLIP.git"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "5c24db59-82a3-4852-b4dc-2889d703150f",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "62432a84-d1d3-45e3-8233-bca007cf3bd0",
   "metadata": {},
   "outputs": [],
   "source": [
    "from test_time_adaptation.image_generation.image_generator import ImageGenerator"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "fbb6faec-3a9b-46d7-be72-825f01487e57",
   "metadata": {},
   "outputs": [],
   "source": [
    "imagenetA_generator = ImageGenerator()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "032714e4-de94-47c2-b52f-e4f7e7142f01",
   "metadata": {},
   "outputs": [],
   "source": [
    "# generate prompts\n",
    "skipped_classes = imagenetA_generator.generate_prompts(\n",
    "    num_prompts=2,\n",
    "    style_of_picture=\"photograph\",\n",
    "    path=\"/home/sagemaker-user/Domain-Shift-Computer-Vision/imagenetA_generated\",\n",
    "    context_llm = \"/home/sagemaker-user/Domain-Shift-Computer-Vision/test_time_adaptation/image_generation/llm_context.json\"\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2e6741bb-e7e6-4f7e-9e60-0e07ed4b5bab",
   "metadata": {},
   "outputs": [],
   "source": [
    "# generate images\n",
    "from diffusers import StableDiffusionPipeline, StableDiffusionImg2ImgPipeline, DPMSolverMultistepScheduler\n",
    "\n",
    "model_id = \"runwayml/stable-diffusion-v1-5\"\n",
    "pipet2i = StableDiffusionPipeline.from_pretrained(model_id, torch_dtype=torch.float16)\n",
    "pipet2i.scheduler = DPMSolverMultistepScheduler.from_config(pipet2i.scheduler.config)\n",
    "pipet2i = pipet2i.to(\"cuda\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "40087018-acf0-4dd1-94b3-668e16d01ee9",
   "metadata": {},
   "outputs": [],
   "source": [
    "imagenet_a_generated_path = \"/home/sagemaker-user/Domain-Shift-Computer-Vision/imagenetA_generated\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "103c72f4-8900-4f86-9a2e-4df731b313c4",
   "metadata": {},
   "outputs": [],
   "source": [
    "imagenetA_generator.generate_images(path = imagenet_a_generated_path,\n",
    "                                    num_images = 1,\n",
    "                                    image_generation_pipeline = pipet2i,\n",
    "                                    num_inference_steps = 25,\n",
    "                                    guidance_scale = 9,\n",
    "                                    strength=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d969f7f1-a25b-4759-a0fa-87805a374609",
   "metadata": {},
   "source": [
    "## Retrieving Images"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "0a5f8d4c-4c0b-4e59-a36e-2bcac75e28b0",
   "metadata": {},
   "outputs": [],
   "source": [
    "from utility.data.get_data import get_data\n",
    "import clip\n",
    "import torch\n",
    "import torch.nn.functional as F\n",
    "from PIL import Image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "6e5fd05b-238a-4a95-b410-2ade85563a61",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/lib/python3.10/site-packages/torch/utils/data/dataloader.py:561: UserWarning: This DataLoader will create 4 worker processes in total. Our suggested max number of worker in current system is 2, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.\n",
      "  warnings.warn(_create_warning_msg(\n"
     ]
    }
   ],
   "source": [
    "dataloader = get_data(batch_size=32, \n",
    "                      img_root = \"imagenet-a\",\n",
    "                      split_data=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 323,
   "id": "0402185c-8779-4e60-83e7-c692b633069a",
   "metadata": {},
   "outputs": [],
   "source": [
    "candle_img = dataloader.dataset[20][0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "0c45d975-d5de-4788-ae16-14774f9633a7",
   "metadata": {},
   "outputs": [],
   "source": [
    "clip_image_encoder = \"ViT-L/14\"\n",
    "clip_model, preprocess = clip.load(clip_image_encoder)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "1591a9a0-7797-4141-8cad-c03b2ee6bf6d",
   "metadata": {},
   "outputs": [],
   "source": [
    "imagenet_a_generated_path = \"/home/sagemaker-user/Domain-Shift-Computer-Vision/imagenetA_generated\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 381,
   "id": "1b1f0d97-03a1-4672-a393-94b770dcff95",
   "metadata": {},
   "outputs": [],
   "source": [
    "retrieved_images = retrieve_gen_images(img = candle_img,\n",
    "                                       num_images = 30,\n",
    "                                       data_path = imagenet_a_generated_path,\n",
    "                                       clip_model = clip_model,\n",
    "                                       preprocess = preprocess,\n",
    "                                       t2i_images = True,\n",
    "                                       use_t2i_similarity = False,\n",
    "                                       threshold = 0.7)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "58eb8f19-e7b0-4960-9d84-58c86713fb29",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.14"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
