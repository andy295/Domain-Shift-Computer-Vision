{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "b1ddb39b-484b-40a8-a6e1-763d3071ddb9",
   "metadata": {},
   "source": [
    "# Test-Time Adaptation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "1851005d-1fc7-4abd-a04f-5550b7067939",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torchvision.transforms as T\n",
    "import torchvision.models as models\n",
    "import torchvision\n",
    "from test_methods.test import Tester\n",
    "from test_time_adaptation.resnet50_dropout import ResNet50Dropout"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "990934cc-7795-415b-adbd-17227bed3510",
   "metadata": {},
   "outputs": [],
   "source": [
    "imagenet_a_path = \"imagenet-a\"\n",
    "imagenet_b_path = \"imagenetv2-matched-frequency-format-val/\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "5ace4045-d733-4897-95fd-f667a42acc60",
   "metadata": {},
   "outputs": [],
   "source": [
    "device = torch.device(\"cuda\") if torch.cuda.is_available() else torch.device(\"cpu\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "31a14b6b-c730-4fd5-a9a9-6607e098ddb3",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torchvision.transforms as T\n",
    "\n",
    "augmentations = [\n",
    "    T.RandomHorizontalFlip(p=1),\n",
    "    T.RandomVerticalFlip(p=1),\n",
    "    T.RandomRotation(degrees=30),\n",
    "    T.RandomRotation(degrees=60),\n",
    "    T.ColorJitter(brightness=0.2),\n",
    "    T.ColorJitter(contrast=0.2),\n",
    "    T.ColorJitter(saturation=0.2),\n",
    "    T.ColorJitter(hue=0.2),\n",
    "    T.RandomAffine(degrees=0, translate=(0.1, 0.1)),\n",
    "    T.RandomRotation(degrees=15),\n",
    "    T.RandomAdjustSharpness(sharpness_factor=2, p=1),\n",
    "    T.RandomGrayscale(p=1),\n",
    "    T.RandomInvert(p=1),\n",
    "    T.RandomAutocontrast(p=1),\n",
    "    T.GaussianBlur(kernel_size=5),\n",
    "]\n",
    "\n",
    "augmix_augmentations = [\n",
    "    T.AugMix(severity=3, mixture_width=3, chain_depth=3, alpha=1.0),\n",
    "    T.AugMix(severity=2, mixture_width=2, chain_depth=3, alpha=1.0),\n",
    "    T.AugMix(severity=4, mixture_width=4, chain_depth=3, alpha=1.0),\n",
    "    T.AugMix(severity=3, mixture_width=3, chain_depth=3, alpha=1.0),\n",
    "    T.AugMix(severity=2, mixture_width=2, chain_depth=3, alpha=1.0),\n",
    "    T.AugMix(severity=4, mixture_width=4, chain_depth=3, alpha=1.0),\n",
    "    T.AugMix(severity=3, mixture_width=3, chain_depth=3, alpha=1.0),\n",
    "    T.AugMix(severity=2, mixture_width=2, chain_depth=3, alpha=1.0),\n",
    "    T.AugMix(severity=4, mixture_width=4, chain_depth=3, alpha=1.0),\n",
    "    T.AugMix(severity=3, mixture_width=3, chain_depth=3, alpha=1.0),\n",
    "    T.AugMix(severity=2, mixture_width=2, chain_depth=3, alpha=1.0),\n",
    "    T.AugMix(severity=4, mixture_width=4, chain_depth=3, alpha=1.0),\n",
    "    T.AugMix(severity=3, mixture_width=3, chain_depth=3, alpha=1.0),\n",
    "    T.AugMix(severity=2, mixture_width=2, chain_depth=3, alpha=1.0),\n",
    "    T.AugMix(severity=4, mixture_width=4, chain_depth=3, alpha=1.0),\n",
    "    T.AugMix(severity=3, mixture_width=3, chain_depth=3, alpha=1.0),\n",
    "    T.AugMix(severity=2, mixture_width=2, chain_depth=3, alpha=1.0),\n",
    "    T.AugMix(severity=4, mixture_width=4, chain_depth=3, alpha=1.0)\n",
    "]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "08b444fa-d1e4-412d-814f-36ba12981ff0",
   "metadata": {},
   "source": [
    "## Resnet50"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "3e752756-e914-48e7-a203-21ae62dba5ac",
   "metadata": {},
   "outputs": [],
   "source": [
    "exp_path_a = \"/home/sagemaker-user/Domain-Shift-Computer-Vision/experiments/Resnet50_ImagenetA_SGD\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "5cf183bc",
   "metadata": {},
   "outputs": [],
   "source": [
    "MC = {\n",
    "\t\"dropout_rate\": 0.5,\n",
    "\t\"num_samples\": 10,\n",
    "\t\"use_dropout\": False\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "9c522c6a-84b6-453d-8921-5a9af1e9453e",
   "metadata": {},
   "outputs": [],
   "source": [
    "tester_resnet50 = Tester(\n",
    "    model = ResNet50Dropout() if MC['use_dropout'] else models.resnet50,\n",
    "    optimizer = torch.optim.SGD,\n",
    "    exp_path = exp_path_a,\n",
    "    device = device\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "7c6041ec-e1e3-4d1a-a419-f86a79c1ac79",
   "metadata": {},
   "outputs": [],
   "source": [
    "#lr_setting = [{\n",
    "#    \"classifier\" : [[\"fc.weight\", \"fc.bias\"], 0.00025]    \n",
    "#}, 0]\n",
    "lr_setting_sgd = [0.00025] # setting used in MEMO paper for SGD\n",
    "lr_setting_adam = [0.0001] # setting used in MEMO paper for ADAM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "200a4ed2-9d24-4de5-8da4-01c8ade487b1",
   "metadata": {},
   "outputs": [],
   "source": [
    "imagenetV1_weights = models.ResNet50_Weights.IMAGENET1K_V1 # MEMO paper used these weights\n",
    "imagenetV2_weights = models.ResNet50_Weights.IMAGENET1K_V2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "e847161c-c688-4ec6-aaa8-4fbbc67baff5",
   "metadata": {},
   "outputs": [],
   "source": [
    "gen_aug_settings = {\n",
    "    \"clip_img_encoder\" : \"ViT-L/14\",\n",
    "    \"num_img\" : 30,\n",
    "    \"gen_data_path\" : \"/home/sagemaker-user/Domain-Shift-Computer-Vision/imagenetA_generated\",\n",
    "    \"use_t2i_similarity\" : True,\n",
    "    \"t2i_img\" : True,\n",
    "    \"i2i_img\" : False,\n",
    "    \"threshold\" : 0.7\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f1bb98e4-9b44-40b6-b343-3599f1eaff9f",
   "metadata": {},
   "outputs": [],
   "source": [
    "tester_resnet50.test(\n",
    "     augmentations = augmix_augmentations, \n",
    "     num_augmentations = 16,\n",
    "     seed_augmentations = 42,\n",
    "     batch_size = 64, \n",
    "     img_root = imagenet_a_path,\n",
    "     num_adaptation_steps = 2,\n",
    "     MEMO = True,\n",
    "     lr_setting = lr_setting_sgd,\n",
    "     top_augmentations = 0, # if using gen_aug run with 0 bc otherwise might not be used at all\n",
    "     weights_imagenet = imagenetV1_weights,\n",
    "     prior_strength = 16,\n",
    "     TTA = True,\n",
    "     MC = None,\n",
    "     gen_aug_settings = gen_aug_settings\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8e5a3855-f888-4eea-af94-77a123dc58a2",
   "metadata": {},
   "source": [
    "## Image Generation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "1f230e3f-5566-4d7c-863c-835a5ff5a6fc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting ollama\n",
      "  Using cached ollama-0.3.1-py3-none-any.whl.metadata (3.8 kB)\n",
      "Requirement already satisfied: httpx<0.28.0,>=0.27.0 in /opt/conda/lib/python3.10/site-packages (from ollama) (0.27.0)\n",
      "Requirement already satisfied: anyio in /opt/conda/lib/python3.10/site-packages (from httpx<0.28.0,>=0.27.0->ollama) (4.4.0)\n",
      "Requirement already satisfied: certifi in /opt/conda/lib/python3.10/site-packages (from httpx<0.28.0,>=0.27.0->ollama) (2024.7.4)\n",
      "Requirement already satisfied: httpcore==1.* in /opt/conda/lib/python3.10/site-packages (from httpx<0.28.0,>=0.27.0->ollama) (1.0.5)\n",
      "Requirement already satisfied: idna in /opt/conda/lib/python3.10/site-packages (from httpx<0.28.0,>=0.27.0->ollama) (3.7)\n",
      "Requirement already satisfied: sniffio in /opt/conda/lib/python3.10/site-packages (from httpx<0.28.0,>=0.27.0->ollama) (1.3.1)\n",
      "Requirement already satisfied: h11<0.15,>=0.13 in /opt/conda/lib/python3.10/site-packages (from httpcore==1.*->httpx<0.28.0,>=0.27.0->ollama) (0.14.0)\n",
      "Requirement already satisfied: exceptiongroup>=1.0.2 in /opt/conda/lib/python3.10/site-packages (from anyio->httpx<0.28.0,>=0.27.0->ollama) (1.2.2)\n",
      "Requirement already satisfied: typing-extensions>=4.1 in /opt/conda/lib/python3.10/site-packages (from anyio->httpx<0.28.0,>=0.27.0->ollama) (4.12.2)\n",
      "Using cached ollama-0.3.1-py3-none-any.whl (10 kB)\n",
      "Installing collected packages: ollama\n",
      "Successfully installed ollama-0.3.1\n"
     ]
    }
   ],
   "source": [
    "!pip install ollama"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "20c37523-1bff-415c-b483-523e0b4a15ad",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting diffusers\n",
      "  Using cached diffusers-0.30.1-py3-none-any.whl.metadata (18 kB)\n",
      "Requirement already satisfied: importlib-metadata in /opt/conda/lib/python3.10/site-packages (from diffusers) (6.10.0)\n",
      "Requirement already satisfied: filelock in /opt/conda/lib/python3.10/site-packages (from diffusers) (3.15.4)\n",
      "Requirement already satisfied: huggingface-hub>=0.23.2 in /opt/conda/lib/python3.10/site-packages (from diffusers) (0.24.3)\n",
      "Requirement already satisfied: numpy in /opt/conda/lib/python3.10/site-packages (from diffusers) (1.26.4)\n",
      "Requirement already satisfied: regex!=2019.12.17 in /opt/conda/lib/python3.10/site-packages (from diffusers) (2024.7.24)\n",
      "Requirement already satisfied: requests in /opt/conda/lib/python3.10/site-packages (from diffusers) (2.32.3)\n",
      "Requirement already satisfied: safetensors>=0.3.1 in /opt/conda/lib/python3.10/site-packages (from diffusers) (0.4.3)\n",
      "Requirement already satisfied: Pillow in /opt/conda/lib/python3.10/site-packages (from diffusers) (10.4.0)\n",
      "Requirement already satisfied: fsspec>=2023.5.0 in /opt/conda/lib/python3.10/site-packages (from huggingface-hub>=0.23.2->diffusers) (2023.6.0)\n",
      "Requirement already satisfied: packaging>=20.9 in /opt/conda/lib/python3.10/site-packages (from huggingface-hub>=0.23.2->diffusers) (23.2)\n",
      "Requirement already satisfied: pyyaml>=5.1 in /opt/conda/lib/python3.10/site-packages (from huggingface-hub>=0.23.2->diffusers) (6.0.1)\n",
      "Requirement already satisfied: tqdm>=4.42.1 in /opt/conda/lib/python3.10/site-packages (from huggingface-hub>=0.23.2->diffusers) (4.66.4)\n",
      "Requirement already satisfied: typing-extensions>=3.7.4.3 in /opt/conda/lib/python3.10/site-packages (from huggingface-hub>=0.23.2->diffusers) (4.12.2)\n",
      "Requirement already satisfied: zipp>=0.5 in /opt/conda/lib/python3.10/site-packages (from importlib-metadata->diffusers) (3.19.2)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in /opt/conda/lib/python3.10/site-packages (from requests->diffusers) (3.3.2)\n",
      "Requirement already satisfied: idna<4,>=2.5 in /opt/conda/lib/python3.10/site-packages (from requests->diffusers) (3.7)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in /opt/conda/lib/python3.10/site-packages (from requests->diffusers) (1.26.19)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /opt/conda/lib/python3.10/site-packages (from requests->diffusers) (2024.7.4)\n",
      "Using cached diffusers-0.30.1-py3-none-any.whl (2.6 MB)\n",
      "Installing collected packages: diffusers\n",
      "Successfully installed diffusers-0.30.1\n"
     ]
    }
   ],
   "source": [
    "!pip install diffusers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "c46a892a-b689-41cf-9a1a-c208df0f70d4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting git+https://github.com/openai/CLIP.git\n",
      "  Cloning https://github.com/openai/CLIP.git to /tmp/pip-req-build-ifxyt60m\n",
      "  Running command git clone --filter=blob:none --quiet https://github.com/openai/CLIP.git /tmp/pip-req-build-ifxyt60m\n",
      "  Resolved https://github.com/openai/CLIP.git to commit dcba3cb2e2827b402d2701e7e1c7d9fed8a20ef1\n",
      "  Preparing metadata (setup.py) ... \u001b[?25ldone\n",
      "\u001b[?25hCollecting ftfy (from clip==1.0)\n",
      "  Using cached ftfy-6.2.3-py3-none-any.whl.metadata (7.8 kB)\n",
      "Requirement already satisfied: packaging in /opt/conda/lib/python3.10/site-packages (from clip==1.0) (23.2)\n",
      "Requirement already satisfied: regex in /opt/conda/lib/python3.10/site-packages (from clip==1.0) (2024.7.24)\n",
      "Requirement already satisfied: tqdm in /opt/conda/lib/python3.10/site-packages (from clip==1.0) (4.66.4)\n",
      "Requirement already satisfied: torch in /opt/conda/lib/python3.10/site-packages (from clip==1.0) (2.0.0.post200)\n",
      "Requirement already satisfied: torchvision in /opt/conda/lib/python3.10/site-packages (from clip==1.0) (0.15.2a0+ab7b3e6)\n",
      "Requirement already satisfied: wcwidth<0.3.0,>=0.2.12 in /opt/conda/lib/python3.10/site-packages (from ftfy->clip==1.0) (0.2.13)\n",
      "Requirement already satisfied: filelock in /opt/conda/lib/python3.10/site-packages (from torch->clip==1.0) (3.15.4)\n",
      "Requirement already satisfied: typing-extensions in /opt/conda/lib/python3.10/site-packages (from torch->clip==1.0) (4.12.2)\n",
      "Requirement already satisfied: sympy in /opt/conda/lib/python3.10/site-packages (from torch->clip==1.0) (1.13.0)\n",
      "Requirement already satisfied: networkx in /opt/conda/lib/python3.10/site-packages (from torch->clip==1.0) (3.3)\n",
      "Requirement already satisfied: jinja2 in /opt/conda/lib/python3.10/site-packages (from torch->clip==1.0) (3.1.4)\n",
      "Requirement already satisfied: numpy in /opt/conda/lib/python3.10/site-packages (from torchvision->clip==1.0) (1.26.4)\n",
      "Requirement already satisfied: requests in /opt/conda/lib/python3.10/site-packages (from torchvision->clip==1.0) (2.32.3)\n",
      "Requirement already satisfied: pillow!=8.3.*,>=5.3.0 in /opt/conda/lib/python3.10/site-packages (from torchvision->clip==1.0) (10.4.0)\n",
      "Requirement already satisfied: MarkupSafe>=2.0 in /opt/conda/lib/python3.10/site-packages (from jinja2->torch->clip==1.0) (2.1.5)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in /opt/conda/lib/python3.10/site-packages (from requests->torchvision->clip==1.0) (3.3.2)\n",
      "Requirement already satisfied: idna<4,>=2.5 in /opt/conda/lib/python3.10/site-packages (from requests->torchvision->clip==1.0) (3.7)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in /opt/conda/lib/python3.10/site-packages (from requests->torchvision->clip==1.0) (1.26.19)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /opt/conda/lib/python3.10/site-packages (from requests->torchvision->clip==1.0) (2024.7.4)\n",
      "Requirement already satisfied: mpmath<1.4,>=1.1.0 in /opt/conda/lib/python3.10/site-packages (from sympy->torch->clip==1.0) (1.3.0)\n",
      "Using cached ftfy-6.2.3-py3-none-any.whl (43 kB)\n",
      "Building wheels for collected packages: clip\n",
      "  Building wheel for clip (setup.py) ... \u001b[?25ldone\n",
      "\u001b[?25h  Created wheel for clip: filename=clip-1.0-py3-none-any.whl size=1369492 sha256=4370ca1c72af42307613be47d11f71c3c1e754fa3964595aa578431efeab616b\n",
      "  Stored in directory: /tmp/pip-ephem-wheel-cache-3lfevf6l/wheels/da/2b/4c/d6691fa9597aac8bb85d2ac13b112deb897d5b50f5ad9a37e4\n",
      "Successfully built clip\n",
      "Installing collected packages: ftfy, clip\n",
      "Successfully installed clip-1.0 ftfy-6.2.3\n"
     ]
    }
   ],
   "source": [
    "! pip install git+https://github.com/openai/CLIP.git"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "5c24db59-82a3-4852-b4dc-2889d703150f",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "62432a84-d1d3-45e3-8233-bca007cf3bd0",
   "metadata": {},
   "outputs": [],
   "source": [
    "from test_time_adaptation.image_generation.image_generator import ImageGenerator"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "fbb6faec-3a9b-46d7-be72-825f01487e57",
   "metadata": {},
   "outputs": [],
   "source": [
    "imagenetA_generator = ImageGenerator()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "032714e4-de94-47c2-b52f-e4f7e7142f01",
   "metadata": {},
   "outputs": [],
   "source": [
    "# generate prompts\n",
    "skipped_classes = imagenetA_generator.generate_prompts(\n",
    "    num_prompts_per_class=20,\n",
    "    style_of_picture=\"photograph\",\n",
    "    path=\"/home/sagemaker-user/Domain-Shift-Computer-Vision/imagenetA_generated\",\n",
    "    context_llm = \"/home/sagemaker-user/Domain-Shift-Computer-Vision/test_time_adaptation/image_generation/llm_context.json\",\n",
    "    llm_model = \"llama3.1\", \n",
    "    clip_text_encoder = \"ViT-L/14\"\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2e6741bb-e7e6-4f7e-9e60-0e07ed4b5bab",
   "metadata": {},
   "outputs": [],
   "source": [
    "# generate images\n",
    "from diffusers import StableDiffusionPipeline, StableDiffusionImg2ImgPipeline, DPMSolverMultistepScheduler\n",
    "\n",
    "model_id = \"runwayml/stable-diffusion-v1-5\"\n",
    "pipet2i = StableDiffusionPipeline.from_pretrained(model_id, torch_dtype=torch.float16)\n",
    "pipet2i.scheduler = DPMSolverMultistepScheduler.from_config(pipet2i.scheduler.config)\n",
    "pipet2i = pipet2i.to(\"cuda\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "40087018-acf0-4dd1-94b3-668e16d01ee9",
   "metadata": {},
   "outputs": [],
   "source": [
    "imagenet_a_generated_path = \"/home/sagemaker-user/Domain-Shift-Computer-Vision/imagenetA_generated\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "103c72f4-8900-4f86-9a2e-4df731b313c4",
   "metadata": {},
   "outputs": [],
   "source": [
    "imagenetA_generator.generate_images(path = imagenet_a_generated_path,\n",
    "                                    num_images = 1,\n",
    "                                    image_generation_pipeline = pipet2i,\n",
    "                                    num_inference_steps = 25,\n",
    "                                    guidance_scale = 9,\n",
    "                                    strength=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d969f7f1-a25b-4759-a0fa-87805a374609",
   "metadata": {},
   "source": [
    "## Retrieving Images"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "0a5f8d4c-4c0b-4e59-a36e-2bcac75e28b0",
   "metadata": {},
   "outputs": [],
   "source": [
    "from utility.data.get_data import get_data\n",
    "import clip\n",
    "import torch\n",
    "import torch.nn.functional as F\n",
    "from PIL import Image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "6e5fd05b-238a-4a95-b410-2ade85563a61",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/lib/python3.10/site-packages/torch/utils/data/dataloader.py:561: UserWarning: This DataLoader will create 4 worker processes in total. Our suggested max number of worker in current system is 2, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.\n",
      "  warnings.warn(_create_warning_msg(\n"
     ]
    }
   ],
   "source": [
    "dataloader = get_data(batch_size=32, \n",
    "                      img_root = \"imagenet-a\",\n",
    "                      split_data=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 323,
   "id": "0402185c-8779-4e60-83e7-c692b633069a",
   "metadata": {},
   "outputs": [],
   "source": [
    "candle_img = dataloader.dataset[20][0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "0c45d975-d5de-4788-ae16-14774f9633a7",
   "metadata": {},
   "outputs": [],
   "source": [
    "clip_image_encoder = \"ViT-L/14\"\n",
    "clip_model, preprocess = clip.load(clip_image_encoder)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "1591a9a0-7797-4141-8cad-c03b2ee6bf6d",
   "metadata": {},
   "outputs": [],
   "source": [
    "imagenet_a_generated_path = \"/home/sagemaker-user/Domain-Shift-Computer-Vision/imagenetA_generated\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 381,
   "id": "1b1f0d97-03a1-4672-a393-94b770dcff95",
   "metadata": {},
   "outputs": [],
   "source": [
    "retrieved_images = retrieve_gen_images(img = candle_img,\n",
    "                                       num_images = 30,\n",
    "                                       data_path = imagenet_a_generated_path,\n",
    "                                       clip_model = clip_model,\n",
    "                                       preprocess = preprocess,\n",
    "                                       t2i_images = True,\n",
    "                                       use_t2i_similarity = False,\n",
    "                                       threshold = 0.7)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5645440d-73ac-4ebd-8735-ebc5fb377702",
   "metadata": {},
   "source": [
    "## Scraping Images"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "4755f1cb-5c15-4239-90ec-b6c2707feb4c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting bing_image_downloader\n",
      "  Using cached bing_image_downloader-1.1.2-py3-none-any.whl.metadata (2.8 kB)\n",
      "Using cached bing_image_downloader-1.1.2-py3-none-any.whl (5.9 kB)\n",
      "Installing collected packages: bing_image_downloader\n",
      "Successfully installed bing_image_downloader-1.1.2\n"
     ]
    }
   ],
   "source": [
    "!pip install bing_image_downloader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "f2f100a7-3514-4d7b-81d3-1f843710e8b6",
   "metadata": {},
   "outputs": [],
   "source": [
    "from test_time_adaptation.image_generation.web_scrape import scrape_images_imagenetA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "9f155692-1fbd-48dc-8d70-ad3437faea4e",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing class: acorn: 100%|██████████| 200/200 [00:00<00:00, 1191.83it/s]                   \n"
     ]
    }
   ],
   "source": [
    "scrape_images_imagenetA(img_style = \"a photo of\", \n",
    "                        imgenetA_gen_path = \"/home/sagemaker-user/Domain-Shift-Computer-Vision/imagenetA_generated\", \n",
    "                        limit = 5)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.14"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
